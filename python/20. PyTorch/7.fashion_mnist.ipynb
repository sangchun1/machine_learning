{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "# 다운로드하여 압축을 풀고 fashion-mnist\\data\\fashion 디렉토리의 ~ubyte.gz 파일을 c:/data/fashion-mnist 디렉토리에 복사\n",
    "import torch\n",
    "# Default CUDA device\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "#이미지 압축파일을 오픈\n",
    "with gzip.open('c:/data/fashion-mnist/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    # frombuffer(바이트배열, 자료형, 시작점)\n",
    "    mnist_data=np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # 차원 변경\n",
    "    mnist_data = mnist_data.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mnist_data = mnist_data / 255\n",
    "pd.DataFrame(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이미지의 라벨\n",
    "with gzip.open('c:/data/fashion-mnist/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    mnist_label=np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "mnist_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(mnist_data,mnist_label,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 1, 28, 28])\n",
      "torch.Size([48000])\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 텐서 변환\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "# 검증용 데이터 텐서 변환\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "# 변환된 텐서의 샘플수 확인\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서를 gpu로 옮기고\n",
    "X_train=X_train.cuda()\n",
    "y_train=y_train.cuda()\n",
    "X_test=X_test.cuda()\n",
    "y_test=y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   9.,  62.,  52.,  41.,  37.,  38.,  36.,  29.,  23.,  25.,\n",
      "           24.,  24.,  25.,  25.,  25.,  25.,  25.,  24.,  25.,  25.,  24.,\n",
      "           27.,  29.,  33.,  36.,  45.,  24.],\n",
      "         [  0.,  39., 116.,  72.,  87.,  85.,  91.,  90.,  91.,  97.,  96.,\n",
      "           97.,  98.,  94.,  94.,  94.,  95.,  95.,  94.,  94.,  92.,  94.,\n",
      "           88.,  92.,  98.,  89.,  95.,  74.],\n",
      "         [  0.,  43.,  92.,  66.,  74.,  78.,  75.,  78.,  76.,  76.,  77.,\n",
      "           73.,  72.,  70.,  70.,  71.,  70.,  69.,  68.,  69.,  71.,  72.,\n",
      "           69.,  74.,  73.,  65.,  64.,  62.],\n",
      "         [  0.,  22.,  97.,  74.,  81.,  87.,  79.,  82.,  82.,  84.,  84.,\n",
      "           78.,  77.,  77.,  78.,  77.,  77.,  75.,  72.,  73.,  74.,  75.,\n",
      "           74.,  78.,  75.,  72.,  69.,  72.],\n",
      "         [  0.,  73.,  87.,  85.,  87.,  84.,  82.,  84.,  82.,  86.,  85.,\n",
      "           82.,  82.,  81.,  78.,  77.,  78.,  78.,  76.,  76.,  76.,  76.,\n",
      "           73.,  77.,  78.,  76.,  73.,  72.],\n",
      "         [ 30., 183.,  58.,  83.,  86.,  84.,  82.,  85.,  81.,  85.,  83.,\n",
      "           79.,  83.,  81.,  76.,  75.,  75.,  78.,  82.,  79.,  77.,  76.,\n",
      "           74.,  78.,  77.,  73.,  69.,  68.],\n",
      "         [  1., 139.,  69.,  73.,  89.,  84.,  83.,  83.,  77.,  82.,  76.,\n",
      "           73.,  84.,  81.,  73.,  69.,  73.,  77.,  79.,  76.,  74.,  70.,\n",
      "           72.,  82.,  73.,  71.,  66.,  79.],\n",
      "         [  3., 155.,  86.,  99.,  72.,  71.,  76.,  81.,  78.,  78.,  84.,\n",
      "           89.,  64.,  71.,  76.,  76.,  64.,  85.,  77.,  71.,  79.,  69.,\n",
      "           75.,  81.,  77.,  61.,  77.,  82.],\n",
      "         [  0., 158.,  27.,  94., 123.,  99.,  82.,  74.,  76.,  78.,  66.,\n",
      "           61.,  73.,  54.,  61.,  52.,  45.,  55.,  59.,  65.,  64.,  55.,\n",
      "           58.,  66.,  73.,  86.,  96.,  43.],\n",
      "         [  0., 230.,  18.,  24.,  61., 117., 143., 145., 156., 141., 135.,\n",
      "          119., 255., 211., 210., 215., 234., 162.,  98., 129., 119., 113.,\n",
      "          123., 125., 123.,  83.,   2.,  44.],\n",
      "         [  0., 209.,  12.,  47.,  37.,  27.,  23.,  28.,  23.,  30.,  11.,\n",
      "           75.,  50.,   0.,   0.,   0.,  58., 139.,  18.,  58.,  56.,  55.,\n",
      "           57.,  42.,  10.,   1.,   6.,  62.],\n",
      "         [ 22., 172.,   1.,  45.,  56.,  42.,  35.,  29.,  37.,  37.,  34.,\n",
      "           56., 167., 193., 185., 180., 168.,  68.,   1.,  15.,  12.,   8.,\n",
      "            8.,   6.,  16.,  31.,   6.,  59.],\n",
      "         [ 49., 183.,   3.,  45.,  45.,  34.,  34.,  43.,  48.,  43.,  47.,\n",
      "           36.,  30., 136., 141., 168.,  68.,   5.,  39.,  37.,  36.,  36.,\n",
      "           32.,  24.,  20.,  25.,  11.,  68.],\n",
      "         [ 66., 190.,   4.,  38.,  68.,  84.,  57.,  47.,  48.,  48.,  44.,\n",
      "           46.,  36.,   9.,   1.,   1.,   6.,  33.,  32.,  38.,  35.,  36.,\n",
      "           35.,  23.,  18.,  18.,  12.,  57.],\n",
      "         [ 58., 194.,  54.,  23.,  59.,  32.,  37.,  39.,  41.,  44.,  45.,\n",
      "           43.,  52.,  56.,  59.,  62.,  55.,  50.,  50.,  47.,  46.,  46.,\n",
      "           55.,  57.,  19.,  43.,  14.,  59.],\n",
      "         [ 96., 165.,  16.,  21.,  24.,  46.,  75.,  74.,  65.,  55.,  52.,\n",
      "           42.,  44.,  47.,  60.,  83., 103., 103.,  91.,  89.,  91.,  66.,\n",
      "           71., 110.,  79.,  14.,  46.,  43.],\n",
      "         [127., 179., 110., 186., 203., 151., 142., 154., 132., 125., 154.,\n",
      "          176., 178., 149., 118.,  76.,  46.,  41.,  62.,  72.,  90.,  76.,\n",
      "           41.,  54.,  86.,  75.,  92.,   0.],\n",
      "         [ 65., 211.,  33.,   2.,  65.,  98., 130., 149., 164., 154., 143.,\n",
      "          149., 144., 141., 142., 151., 183., 159., 115.,  32.,  58.,  61.,\n",
      "           73.,  77.,  76.,  51.,   2.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,  59., 177., 193., 182., 125., 130.,\n",
      "          122., 130., 144., 135., 140., 142., 140.,  82.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   1.,   4.,   0.,  39., 179., 130., 132., 162., 170.,\n",
      "          162., 150., 137., 108.,  90.,  82.,  75.,  29.,   0.,   1.,   0.,\n",
      "            0.,   0.,   4.,   4.,   0.,   0.],\n",
      "         [  0.,   1.,   0.,   1.,   0.,   0.,  29.,  68.,  73.,  89.,  92.,\n",
      "           89.,  76.,  47.,  28.,  16.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
      "            0.,   2.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.]]], device='cuda:0'), tensor(8, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 독립변수와 종속변수 텐서를 합침\n",
    "train = TensorDataset(X_train, y_train)\n",
    "# 텐서의 첫 번째 데이터를 확인\n",
    "print(train[0])\n",
    "# 미니배치 분할\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 입력 채널 수, 출력 채널 수, 필터 크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "model = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_15168\\1884579451.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(99.2718, device='cuda:0')\n",
      "100 tensor(69.8922, device='cuda:0')\n",
      "150 tensor(56.2991, device='cuda:0')\n",
      "200 tensor(48.9458, device='cuda:0')\n",
      "250 tensor(50.9358, device='cuda:0')\n",
      "300 tensor(60.0297, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train) # 계산 그래프 구성\n",
    "        #텐서를 gpu로 이동시킴\n",
    "        X_train=X_train.cuda()\n",
    "        y_train=y_train.cuda()\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(X_train)\n",
    "        # 오차계산\n",
    "        loss = criterion(output, y_train)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        # 50회 반복마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_15168\\1884579451.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8536666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "# 출력이 0 또는 1이 되게 함\n",
    "result = torch.max(model(X_test).data, 1)[1]\n",
    "# 모형의 정확도 측정\n",
    "# gpu에 저장된 텐서를 cpu로 이동시킴\n",
    "y_test=y_test.cpu()\n",
    "result=result.cpu()\n",
    "accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
