{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.단어사전기반 분석 - 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함\n",
    "# 텍스트와 감성지수가 사전에 정의되어 있어야 함\n",
    "import glob\n",
    "# pip install afinn\n",
    "from afinn import Afinn\n",
    "#imdb 데이터셋 5만건의 학습용,검증용 데이터셋 긍정,부정 리뷰로 라벨링되어 있음.\n",
    "#긍정리뷰데이터 20번째 내용\n",
    "# glob.glob 특정한 패턴의 파일만 선택하는 함수\n",
    "pos_review=(glob.glob(\"c:/data/imdb/train/pos/*.txt\"))[20]\n",
    "f = open(pos_review, 'r')\n",
    "#파일을 읽음\n",
    "lines1 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#감성분석 객체\n",
    "afinn = Afinn()\n",
    "#텍스트 전처리 후 감성점수 산출\n",
    "afinn.score(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/pos\\\\0_9.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10000_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10001_10.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10002_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10003_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10004_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10005_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10006_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10007_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/data/imdb/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 긍정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()\n",
    "#부정리뷰데이터 20번째 내용\n",
    "neg_review=(glob.glob(\"c:/data/imdb/train/neg/*.txt\"))[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(neg_review, 'r')\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/neg\\\\0_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10000_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10001_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10002_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10003_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10004_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10005_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10006_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10007_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/data/imdb/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 부정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.기계학습으로 감성분석(시간이 매우 오래 걸림)\n",
    "import glob\n",
    "#긍정 텍스트 로딩\n",
    "pos_review=(glob.glob(\"c:/data/imdb/train/pos/*.txt\")[:100])\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정 텍스트 로딩\n",
    "neg_review=(glob.glob(\"c:/data/imdb/train/neg/*.txt\")[:100])\n",
    "lines_neg=[]\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정,부정 리뷰를 합침\n",
    "total_text=lines_pos+lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#긍정,부정 클래스 라벨링\n",
    "x = np.array([\"pos\", \"neg\"])\n",
    "class_Index=np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어들에 Tfidf 가중치를 부여한 후 문서-단어 매트릭스로 바꿈\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bromwell</th>\n",
       "      <th>high</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>comedy</th>\n",
       "      <th>ran</th>\n",
       "      <th>time</th>\n",
       "      <th>programs</th>\n",
       "      <th>school</th>\n",
       "      <th>life</th>\n",
       "      <th>teachers</th>\n",
       "      <th>...</th>\n",
       "      <th>zombified</th>\n",
       "      <th>auteur</th>\n",
       "      <th>ample</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>golden</th>\n",
       "      <th>geist</th>\n",
       "      <th>uttered</th>\n",
       "      <th>downloading</th>\n",
       "      <th>midget</th>\n",
       "      <th>tricking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bromwell  high  cartoon  comedy  ran  time  programs  school  life  \\\n",
       "0       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "1       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "2       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "3       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "4       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "\n",
       "   teachers  ...  zombified  auteur  ample  opportunities  golden  geist  \\\n",
       "0       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "1       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "2       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "3       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "4       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "\n",
       "   uttered  downloading  midget  tricking  \n",
       "0      0.0          0.0     0.0       0.0  \n",
       "1      0.0          0.0     0.0       0.0  \n",
       "2      0.0          0.0     0.0       0.0  \n",
       "3      0.0          0.0     0.0       0.0  \n",
       "4      0.0          0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 6514 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#데이터프레임으로 변환\n",
    "df=pd.DataFrame(X_train_vectorized.toarray(), columns=vect.vocabulary_.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀 모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.10075971571307776\n",
      "189 0.10075971571307776\n",
      "212 0.09519036398460193\n",
      "583 0.06607233108770873\n",
      "770 0.4344371044102009\n",
      "813 0.10075971571307776\n",
      "889 0.09087043917100991\n",
      "1034 0.07745152705306162\n",
      "1062 0.09519036398460193\n",
      "1101 0.07093762711956966\n",
      "1916 0.09087043917100991\n",
      "2029 0.07093762711956966\n",
      "2121 0.06502562223418444\n",
      "2167 0.10860927610255022\n",
      "2202 0.10075971571307776\n",
      "2719 0.34800983331794577\n",
      "2895 0.10075971571307776\n",
      "3000 0.10860927610255022\n",
      "3005 0.10860927610255022\n",
      "3239 0.07949124320565701\n",
      "3310 0.09087043917100991\n",
      "3377 0.04921361834843082\n",
      "3397 0.06835253974870535\n",
      "3553 0.04749164856850098\n",
      "3818 0.040058435364654435\n",
      "4021 0.03193031768060858\n",
      "4168 0.09087043917100991\n",
      "4231 0.10860927610255022\n",
      "4277 0.10075971571307776\n",
      "4347 0.10860927610255022\n",
      "4469 0.10075971571307776\n",
      "4476 0.10860927610255022\n",
      "4606 0.10075971571307776\n",
      "4652 0.09519036398460193\n",
      "4664 0.10860927610255022\n",
      "4745 0.09087043917100991\n",
      "4760 0.10075971571307776\n",
      "4860 0.0630880667300972\n",
      "4944 0.10860927610255022\n",
      "4980 0.10860927610255022\n",
      "4989 0.06502562223418444\n",
      "5008 0.15121275870390602\n",
      "5010 0.10860927610255022\n",
      "5024 0.10860927610255022\n",
      "5064 0.040058435364654435\n",
      "5259 0.07745152705306162\n",
      "5554 0.19038072796920386\n",
      "5555 0.21721855220510045\n",
      "5665 0.09087043917100991\n",
      "5742 0.4344371044102009\n",
      "5744 0.10860927610255022\n",
      "5831 0.047084067241284604\n",
      "5881 0.0403410593324844\n",
      "6016 0.08177145186665363\n",
      "6339 0.09519036398460193\n",
      "6364 0.06403261493511332\n",
      "6482 0.054933627630757056\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(X_train_vectorized[0].toarray()[0]):\n",
    "    if value>0:\n",
    "        print(idx, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰들을 하나씩 불러와서 실험\n",
    "def pos_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests1=[]\n",
    "    for idx in range(0,num):\n",
    "        pos_review_test=(glob.glob(\"c:/data/imdb/test/pos/*.txt\"))[idx]\n",
    "        f = open(pos_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result=pred[0]\n",
    "        if result==\"pos\":\n",
    "            count+=1\n",
    "        count_all += 1\n",
    "    rate= count*100/count_all\n",
    "    print(f\"분류정확도:{rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부정 리뷰들을 하나씩 불러와서 실험\n",
    "def neg_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests2=[]\n",
    "    for idx in range(0,num):\n",
    "        neg_review_test=(glob.glob(\"c:/data/imdb/test/neg/*.txt\"))[idx]\n",
    "        f = open(neg_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests2:\n",
    "        preds = model.predict(vect.transform(test))\n",
    "        result=preds[0]\n",
    "        if result==\"neg\":\n",
    "            count+=1\n",
    "        count_all+=1\n",
    "    rate= count*100/count_all\n",
    "    print(\"예측정확도:{0:.1f}%\".format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:66.0%\n",
      "예측정확도:82.0%\n"
     ]
    }
   ],
   "source": [
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:54.0%\n",
      "예측정확도:54.0%\n"
     ]
    }
   ],
   "source": [
    "#의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:46.0%\n",
      "예측정확도:70.0%\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#10개의 트리로 구성된 랜덤 포레스트\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:34.0%\n",
      "예측정확도:85.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:76.0%\n"
     ]
    }
   ],
   "source": [
    "#인공신경망\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:86.0%\n"
     ]
    }
   ],
   "source": [
    "#SVM 모형\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
